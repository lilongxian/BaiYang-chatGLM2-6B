# LL-BaiYang

本项目对清华2023-06-25开源的chatGLM2-6B模型进行了模型网络建设、数据建模等全部技术的反向研究（关键地方做了注释，并修复了tokenizer脚本）。并尝试复现其指令微调训练模型。

支持清华chatGLM-6B模型的微调训练数据格式要求，并扩展支持了alpaca指令微调训练数据格式。

本项目技术参考、引用了清华chatGLM-6B、chatGLM2-6B部分代码。

若你使用本项目，请著名清华知识产权。

本项目开源，不保证商业化效果，仅供学术研究使用。

# 友情链接
https://github.com/THUDM/ChatGLM2-6B

# 邮箱
whpxty5518@163.com / 17719085580（wx） Li·Long 


