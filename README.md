# LL-BaiYang

本项目对清华2023-06-25开源的chatGLM2-6B模型进行了模型网络建设、数据建模等全部技术的反向研究（关键地方做了注释，并修复了tokenization脚本中的bug）。并尝试复现其指令微调训练模型。

1. 支持清华chatGLM-6B模型的微调训练数据格式要求，并扩展支持了alpaca指令微调训练数据格式。

2. 本项目技术参考、引用了清华chatGLM-6B、chatGLM2-6B部分代码。

3. 若你使用本项目，请注名引用清华知识产权。

4. 本项目开源，不保证商业化效果，仅供学术研究使用。


# Update
1. 2023-07-04： 首次开源，与清华官方微调训练模型开源时间同步。

# chatGLM2-6B新技术原理与代码实现深度解析
  文档还在构件中...
  如果你想第一时间彻底全面了解chatGLM2-6B全部的新技术原理以及GLM2中的代码实现思路，可以通过最下面的联系方式了解。


# 友情链接
https://github.com/THUDM/ChatGLM2-6B

# 联系方式
whpxty5518@163.com / 17719085580（wx） Li·Long 


